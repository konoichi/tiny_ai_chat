# ğŸ› ï¸ NavyYard

Ein modularer, lokaler KI-Chatbot mit Charakter â€“ lÃ¤uft direkt auf deinem Rechner, keine Cloud, keine Gnade. Entwickelt mit Fokus auf:

* ğŸ“¦ ModularitÃ¤t
* ğŸ Professionelles Logging & Debugging
* ğŸ¤– Dynamische Personas
* ğŸ§  Kontextuelles GedÃ¤chtnis

---

## ğŸš€ Features

* **Streaming-Ausgabe**: Antworten Token fÃ¼r Token mit `!stream on/off`
* **Persona-System**: WÃ¤hle `!persona abby`, `!persona sage` etc.
* **Farbausgabe**: Bot & User in unterschiedlichen Farben (via `colorama`)
* **Kontextverlauf**: Verlauf wird speicherbar & bearbeitbar
* **Debug-Modus**: Kontrolliert die Modell-Ausgabe (`llama_perf_context_print` etc.)
* **Umweltvariable**: Debug setzt intern `LLAMA_PERF_DISABLE=0/1`
* **Selbsttest**: `selftest` prÃ¼ft wichtige Komponenten
* **Modelle flexibel austauschbar**: Nutzung beliebiger GGUF-Modelle lokal mit GPU/CPU

* **Status-Banner**: Zeigt aktives Modell, Hardware-Modus und Persona beim Start und nach Ã„nderungen
* **Hardware-Erkennung**: Automatische Erkennung und Anzeige von CPU/GPU-Modus und GPU-Layern
* **Sofortige Modellbefehle**: `!model <n>` funktioniert direkt nach dem Start ohne vorheriges `!models`
* **Optimiertes Persona-Switching**: Blitzschneller Wechsel zwischen Personas ohne Modell-Neuladung

---

## âš™ï¸ Installation & Nutzung

### Voraussetzungen

* Python 3.10+
* Eine NVIDIA GPU (fÃ¼r CUDA-beschleunigte Modelle, optional)
* `llama-cpp-python`
* Optional: `colorama`, `pyyaml`, `tqdm`


### Setup (Linux/macOS)

```bash
git clone https://dein.git.repo/navyyard.git
cd navyyard
chmod +x run.sh
./run.sh
```

Das Skript richtet eine virtuelle Umgebung ein, installiert AbhÃ¤ngigkeiten und startet Abby.

---

## ğŸ§  ArchitekturÃ¼berblick

```bash
navyyard/
â”œâ”€â”€ chatbot/
â”‚   â”œâ”€â”€ bot.py              # Hauptklasse AbbyBot
â”‚   â”œâ”€â”€ model_wrapper.py    # Llama-Modell-Wrapper mit Hardware-Erkennung
â”‚   â”œâ”€â”€ memory.py           # Einfacher In-Memory-Verlauf
â”‚   â”œâ”€â”€ prompter.py         # Prompt-Builder fÃ¼r Konversation
â”‚   â”œâ”€â”€ persona_manager.py  # LÃ¤dt Persona-Dateien aus ./personas/
â”‚   â”œâ”€â”€ yaml_persona_manager.py # LÃ¤dt YAML-Persona-Dateien
â”‚   â”œâ”€â”€ status_banner.py    # Status-Banner fÃ¼r Modell- und Hardware-Infos
â”‚   â”œâ”€â”€ model_manager.py    # Modell-Indexierung und -Verwaltung
â”‚   â”œâ”€â”€ model_metadata_cache.py # Cache fÃ¼r Modell-Metadaten
â”‚   
â”‚   â”œâ”€â”€ config.py           # SETTINGS & globale Flags
â”‚   â””â”€â”€ selftest.py         # SystemprÃ¼fung
â”œâ”€â”€ config/                 # Konfigurationsdateien
â”‚   â”œâ”€â”€ personas/           # YAML-Persona-Dateien
â”‚   â””â”€â”€ settings.yaml       # Globale Einstellungen
â”œâ”€â”€ tests/                  # Test-Verzeichnis
â”‚   â”œâ”€â”€ test_hardware_detection.py # Tests fÃ¼r Hardware-Erkennung
â”‚   â”œâ”€â”€ test_status_banner.py # Tests fÃ¼r Status-Banner
â”‚   â”œâ”€â”€ test_integration.py # Integrationstests
â”‚   â””â”€â”€ performance_test.py # Performance-Tests
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ run.sh                  # Erstellt & nutzt virtuelle Umgebung
â”œâ”€â”€ run_tests.sh            # FÃ¼hrt Tests aus
â””â”€â”€ main.py                 # Einstiegspunkt
```

---

## ğŸ’¬ Beispiel-Session

```text
ğŸ§  Abby sagt: Frag mich was! (Aktive Persona: abby)
ğŸ‘¤ Du: !persona sage
ğŸ”„ Persona gewechselt zu: sage
ğŸ‘¤ Du: what time is it?
ğŸ¤– Sage: It's 02:34 AM. Shouldn't you be sleeping? ğŸ˜
ğŸ‘¤ Du: tell me a joke
ğŸ¤– Sage: Why don't scientists trust atoms? Because they make up everything!
```

---

## ğŸ§ª Befehle im Chat

```text
ğŸ‘¤ !persona <name>         - Wechsle die aktive Persona
ğŸ” !stream on/off          - Streaming-Modus aktivieren/deaktivieren
ğŸ§¹ !reset                  - Verlauf lÃ¶schen
ğŸ !debug on/off           - Debug-Modus aktivieren/deaktivieren
ğŸ“Š !status                 - Status anzeigen
ğŸ’» !hardware               - Detaillierte Hardware-Informationen anzeigen
ğŸ”¬ !benchmark              - Performance-Benchmark durchfÃ¼hren
ğŸ’€ selftest                - Systemcheck durchfÃ¼hren
ğŸ“¦ !models [--verbose]     - VerfÃ¼gbare Modelle auflisten
ğŸ” !model <n>              - Modell mit Index laden
ğŸ“ !model last_model       - Letztes Modell erneut laden
â„¹ï¸  !model                 - Zeigt Infos zum aktiven Modell (inkl. RAM)

â“ !help                   - Diese Hilfe anzeigen
ğŸšª exit / quit             - Abby verlassen
```

---

## ğŸ“Œ To-Do & Ausbauideen

### Technische Erweiterungen

* [x] ğŸ”„ **LLM-Wechsel zur Laufzeit** (`!model <n>`, `!model last_model`)
* [ ] ğŸ’¾ **LangzeitgedÃ¤chtnis** (z. B. SQLite + Embedding-Suche)
* [ ] ğŸ•’ **Auto-Persona-Switching** (zeit- oder themenbasiert)

* [ ] ğŸ™ï¸ **Voice Input** (Whisper / STT)
* [ ] ğŸ–¼ï¸ **WebUI/GUI** (Gradio, PyQt)

### Persona-System

* [x] ğŸ“„ **YAML-Rollenprofil-Logik**
  * PersÃ¶nlichkeit, Stil, Vorlieben aus YAML-Dateien

  * Zentrale Steuerung & Anpassbarkeit

---

## ğŸ‘¨â€ğŸ”§ FÃ¼r Entwickler

* Nutze `config.py` fÃ¼r zentrale Flags wie `debug`, `streaming` etc.
* Einfache Erweiterbarkeit durch modulare Struktur
* `prompter.py` enthÃ¤lt die System-Persona-Logik
* Alle Prompts/Charaktere liegen in `config/personas/*.yaml`




### Enhanced Model Management

Das erweiterte Modellmanagement bietet verbesserte Funktionen fÃ¼r die Verwaltung und Ãœberwachung von KI-Modellen:

* **Status-Banner**: Zeigt wichtige Informationen zum aktuellen Zustand des Chatbots an:
  * Aktives Modell
  * Hardware-Modus (CPU/GPU)
  * Anzahl der GPU-Layer (falls im GPU-Modus)
  * Aktive Persona
  * Wird beim Start und nach Ã„nderungen automatisch angezeigt

* **Hardware-Erkennung**:
  * Automatische Erkennung des Hardware-Modus (CPU/GPU)
  * Bestimmung der Anzahl der GPU-Layer
  * Erkennung von GPU-Fallbacks (wenn GPU angefordert, aber CPU verwendet wird)
  * Caching des Hardware-Status fÃ¼r verbesserte Performance

* **Modell-Vorindexierung**:
  * Sofortige VerfÃ¼gbarkeit von Modellbefehlen ohne vorherige Indexierung
  * Schnellerer Zugriff auf Modelle durch Caching
  * Persistente Speicherung des zuletzt verwendeten Modells

* **Optimiertes Persona-Switching**:
  * Blitzschneller Wechsel zwischen Personas ohne Modell-Neuladung
  * Aktualisierung nur der relevanten Komponenten (Prompt-Template)
  * Automatische Aktualisierung des Status-Banners nach Persona-Wechsel

* **ZuverlÃ¤ssige GPU-Konfiguration**:
  * Explizite Konfiguration der GPU-Einstellungen bei jedem Modellwechsel
  * ÃœberprÃ¼fung der korrekten Anwendung der GPU-Einstellungen
  * Benutzerbenachrichtigungen bei GPU-Fallbacks oder Konfigurationsproblemen

### Tests und QualitÃ¤tssicherung

Das Projekt enthÃ¤lt umfangreiche Tests zur Sicherstellung der FunktionalitÃ¤t und Performance:

#### AusfÃ¼hren der Tests

```bash
# Alle Tests ausfÃ¼hren
./run_tests.sh

# Spezifische Tests ausfÃ¼hren
python -m pytest tests/test_hardware_detection.py
python -m pytest tests/test_status_banner.py
python -m pytest tests/test_integration.py
```

#### Performance-Tests

```bash
# Alle Performance-Tests ausfÃ¼hren
python tests/performance_test.py

# Nur Startup-Zeit messen
python tests/performance_test.py --startup

# Nur Persona-Switching-Zeit messen
python tests/performance_test.py --persona

# Nur Modell-Ladezeiten messen
python tests/performance_test.py --model

# Anzahl der Iterationen anpassen
python tests/performance_test.py --iterations 5
```

Die Ergebnisse der Performance-Tests werden im Verzeichnis `tests/results/` gespeichert.

#### Test-Typen

* **Unit-Tests**: Testen einzelne Komponenten isoliert
  * `test_hardware_detection.py`: Tests fÃ¼r die Hardware-Erkennung
  * `test_status_banner.py`: Tests fÃ¼r das Status-Banner

* **Integrationstests**: Testen das Zusammenspiel mehrerer Komponenten
  * `test_integration.py`: Tests fÃ¼r die Integration von Modell-Management, Hardware-Erkennung und Status-Banner

* **Performance-Tests**: Messen die Leistung verschiedener Funktionen
  * `performance_test.py`: Tests fÃ¼r Startup-Zeit, Persona-Switching und Modell-Ladezeiten

---

## âœ… Status

Der MVP ist stabil, startet zuverlÃ¤ssig und lÃ¤sst sich um neue Personas, Modelle oder Features leicht erweitern.

Wenn du Lust hast, Abby sprechen zu lassen oder ein echtes LangzeitgedÃ¤chtnis einzubauen â€“ du weiÃŸt, wo du mich findest ğŸ˜

---

**Lizenz**: Noch nicht definiert. Frag den Boss ğŸ˜‰